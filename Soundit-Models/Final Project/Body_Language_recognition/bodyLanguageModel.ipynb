{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b13abe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[66545]: Class CaptureDelegate is implemented in both /Users/kevynkrancenblum/.local/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x2895824e8) and /Users/kevynkrancenblum/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x140588860). One of the two will be used. Which one is undefined.\n",
      "objc[66545]: Class CVWindow is implemented in both /Users/kevynkrancenblum/.local/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x289582538) and /Users/kevynkrancenblum/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x1302a0a68). One of the two will be used. Which one is undefined.\n",
      "objc[66545]: Class CVView is implemented in both /Users/kevynkrancenblum/.local/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x289582560) and /Users/kevynkrancenblum/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x1302a0a90). One of the two will be used. Which one is undefined.\n",
      "objc[66545]: Class CVSlider is implemented in both /Users/kevynkrancenblum/.local/lib/python3.9/site-packages/cv2/cv2.abi3.so (0x289582588) and /Users/kevynkrancenblum/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x1302a0ab8). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a60711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f962593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8043ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "636a8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "start = 0\n",
    "end = 29\n",
    "for i in range(start, end+1):\n",
    "    current_folder_name = '/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/KeypointsData/Sad2/Sad2/' + str(i)\n",
    "    new_folder_name = '/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/KeypointsDataVideo/Sad/'+ str(i + 452)\n",
    "    os.rename(current_folder_name, new_folder_name)\n",
    "    #current_folder_name = '/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/KeypointsData30f copy/Sad/Sad1' + str(i)\n",
    "    #new_folder_name = '/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/KeypointsData/Keypoints/Sad/'+ str(i + 240)\n",
    "    #os.rename(current_folder_name, new_folder_name)\n",
    "    #current_folder_name = '/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/KeypointsData30f copy/Angry/Angry1' + str(i)\n",
    "    #new_folder_name = '/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/KeypointsData/Keypoints/Angry/'+ str(i + 240)\n",
    "    #os.rename(current_folder_name, new_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279e18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose,face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d676b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/KeypointsDataVideo') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['Angry', 'Happy','Sad'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 481\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f1254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bbd9b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df6b7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    if action == 'Sad':\n",
    "        for sequence in range(no_sequences):\n",
    "            window = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "                window.append(res)\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "    elif action == 'Angry':\n",
    "        for sequence in range(362):\n",
    "            window = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "                window.append(res)\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "    else:\n",
    "        for sequence in range(592):\n",
    "            window = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "                window.append(res)\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041e6758",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(sequences)\n\u001b[1;32m      2\u001b[0m y \u001b[39m=\u001b[39m to_categorical(labels)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sequences' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df3b2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout,Activation\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0d3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c16861b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 02:38:26.107790: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-18 02:38:26.107936: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GRU, Dense, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.keras.regularizers import L2\n",
    "\n",
    "input_shape = (30, 1662)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# CNN layers\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# GRU layers\n",
    "model.add(GRU(256, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu', activity_regularizer=L2(0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu', activity_regularizer=L2(0.01)))\n",
    "\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10aad20d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4e28612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 16:43:21.387222: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-08 16:43:21.947327: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-08 16:43:22.053536: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-08 16:43:22.338509: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-08 16:43:22.540083: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 6s 82ms/step - loss: 2.0224 - categorical_accuracy: 0.4343\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 1.4767 - categorical_accuracy: 0.4908\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 2s 43ms/step - loss: 1.2902 - categorical_accuracy: 0.5055\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.1587 - categorical_accuracy: 0.5525\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 1.1078 - categorical_accuracy: 0.5583\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 1.0426 - categorical_accuracy: 0.5884\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 1.0069 - categorical_accuracy: 0.6141\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.9451 - categorical_accuracy: 0.6288\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.9312 - categorical_accuracy: 0.6398\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.9089 - categorical_accuracy: 0.6566\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.8858 - categorical_accuracy: 0.6588\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.8676 - categorical_accuracy: 0.6654\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.8543 - categorical_accuracy: 0.6750\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.8598 - categorical_accuracy: 0.6610\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.8407 - categorical_accuracy: 0.6742\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.8091 - categorical_accuracy: 0.6735\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.8169 - categorical_accuracy: 0.6713\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.8100 - categorical_accuracy: 0.6772\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7957 - categorical_accuracy: 0.6941\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7900 - categorical_accuracy: 0.6772\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.8175 - categorical_accuracy: 0.6684\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7844 - categorical_accuracy: 0.6853\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.7784 - categorical_accuracy: 0.6794\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.7721 - categorical_accuracy: 0.6750\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7572 - categorical_accuracy: 0.6941\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.7758 - categorical_accuracy: 0.6787\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.7684 - categorical_accuracy: 0.6882\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7879 - categorical_accuracy: 0.6838\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.7549 - categorical_accuracy: 0.6867\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7582 - categorical_accuracy: 0.6882\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7443 - categorical_accuracy: 0.6955\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.7399 - categorical_accuracy: 0.6941\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7322 - categorical_accuracy: 0.7117\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.7347 - categorical_accuracy: 0.7161\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6971 - categorical_accuracy: 0.7197\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6934 - categorical_accuracy: 0.7241\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7433 - categorical_accuracy: 0.6948\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.7156 - categorical_accuracy: 0.7109\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7506 - categorical_accuracy: 0.7007\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.7156 - categorical_accuracy: 0.7058\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7696 - categorical_accuracy: 0.6794\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6981 - categorical_accuracy: 0.7256\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7050 - categorical_accuracy: 0.7219\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7013 - categorical_accuracy: 0.7168\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6862 - categorical_accuracy: 0.7300\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.7048 - categorical_accuracy: 0.7234\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6960 - categorical_accuracy: 0.7190\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6714 - categorical_accuracy: 0.7278\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6863 - categorical_accuracy: 0.7256\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6554 - categorical_accuracy: 0.7513\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6719 - categorical_accuracy: 0.7403\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6496 - categorical_accuracy: 0.7410\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6580 - categorical_accuracy: 0.7388\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 2s 50ms/step - loss: 0.6538 - categorical_accuracy: 0.7425\n",
      "Epoch 55/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.6519 - categorical_accuracy: 0.7542\n",
      "Epoch 56/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.6615 - categorical_accuracy: 0.7278\n",
      "Epoch 57/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6653 - categorical_accuracy: 0.7388\n",
      "Epoch 58/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6608 - categorical_accuracy: 0.7293\n",
      "Epoch 59/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.6737 - categorical_accuracy: 0.7315\n",
      "Epoch 60/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6620 - categorical_accuracy: 0.7263\n",
      "Epoch 61/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6535 - categorical_accuracy: 0.7476\n",
      "Epoch 62/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6666 - categorical_accuracy: 0.7461\n",
      "Epoch 63/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6473 - categorical_accuracy: 0.7476\n",
      "Epoch 64/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6146 - categorical_accuracy: 0.7630\n",
      "Epoch 65/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6389 - categorical_accuracy: 0.7535\n",
      "Epoch 66/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6240 - categorical_accuracy: 0.7550\n",
      "Epoch 67/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6124 - categorical_accuracy: 0.7498\n",
      "Epoch 68/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6151 - categorical_accuracy: 0.7579\n",
      "Epoch 69/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6479 - categorical_accuracy: 0.7381\n",
      "Epoch 70/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6340 - categorical_accuracy: 0.7469\n",
      "Epoch 71/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6100 - categorical_accuracy: 0.7733\n",
      "Epoch 72/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6014 - categorical_accuracy: 0.7667\n",
      "Epoch 73/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6083 - categorical_accuracy: 0.7652\n",
      "Epoch 74/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6227 - categorical_accuracy: 0.7572\n",
      "Epoch 75/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.6334 - categorical_accuracy: 0.7359\n",
      "Epoch 76/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6041 - categorical_accuracy: 0.7601\n",
      "Epoch 77/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5652 - categorical_accuracy: 0.7784\n",
      "Epoch 78/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.6061 - categorical_accuracy: 0.7586\n",
      "Epoch 79/500\n",
      "43/43 [==============================] - 2s 50ms/step - loss: 0.5634 - categorical_accuracy: 0.7902\n",
      "Epoch 80/500\n",
      "43/43 [==============================] - 2s 49ms/step - loss: 0.6013 - categorical_accuracy: 0.7652\n",
      "Epoch 81/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.5652 - categorical_accuracy: 0.7733\n",
      "Epoch 82/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.6309 - categorical_accuracy: 0.7476\n",
      "Epoch 83/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5758 - categorical_accuracy: 0.7784\n",
      "Epoch 84/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5589 - categorical_accuracy: 0.7689\n",
      "Epoch 85/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5822 - categorical_accuracy: 0.7682\n",
      "Epoch 86/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.6449 - categorical_accuracy: 0.7344\n",
      "Epoch 87/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5679 - categorical_accuracy: 0.7872\n",
      "Epoch 88/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.5657 - categorical_accuracy: 0.7799\n",
      "Epoch 89/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5772 - categorical_accuracy: 0.7755\n",
      "Epoch 90/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5711 - categorical_accuracy: 0.7770\n",
      "Epoch 91/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5485 - categorical_accuracy: 0.7828\n",
      "Epoch 92/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5475 - categorical_accuracy: 0.7821\n",
      "Epoch 93/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5641 - categorical_accuracy: 0.7806\n",
      "Epoch 94/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5557 - categorical_accuracy: 0.7740\n",
      "Epoch 95/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5514 - categorical_accuracy: 0.7792\n",
      "Epoch 96/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5640 - categorical_accuracy: 0.7601\n",
      "Epoch 97/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5648 - categorical_accuracy: 0.7667\n",
      "Epoch 98/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5558 - categorical_accuracy: 0.7865\n",
      "Epoch 99/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5976 - categorical_accuracy: 0.7645\n",
      "Epoch 100/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5364 - categorical_accuracy: 0.7916\n",
      "Epoch 101/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5354 - categorical_accuracy: 0.7916\n",
      "Epoch 102/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5426 - categorical_accuracy: 0.8026\n",
      "Epoch 103/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5622 - categorical_accuracy: 0.7836\n",
      "Epoch 104/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5491 - categorical_accuracy: 0.7865\n",
      "Epoch 105/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.5390 - categorical_accuracy: 0.7938\n",
      "Epoch 106/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5196 - categorical_accuracy: 0.7997\n",
      "Epoch 107/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.5425 - categorical_accuracy: 0.7902\n",
      "Epoch 108/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5226 - categorical_accuracy: 0.7953\n",
      "Epoch 109/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5171 - categorical_accuracy: 0.7931\n",
      "Epoch 110/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5159 - categorical_accuracy: 0.7982\n",
      "Epoch 111/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5278 - categorical_accuracy: 0.7997\n",
      "Epoch 112/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5208 - categorical_accuracy: 0.7968\n",
      "Epoch 113/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5343 - categorical_accuracy: 0.7777\n",
      "Epoch 114/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5336 - categorical_accuracy: 0.7770\n",
      "Epoch 115/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5277 - categorical_accuracy: 0.7997\n",
      "Epoch 116/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5171 - categorical_accuracy: 0.7990\n",
      "Epoch 117/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5676 - categorical_accuracy: 0.7799\n",
      "Epoch 118/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5327 - categorical_accuracy: 0.7865\n",
      "Epoch 119/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5291 - categorical_accuracy: 0.7968\n",
      "Epoch 120/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5308 - categorical_accuracy: 0.7880\n",
      "Epoch 121/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5205 - categorical_accuracy: 0.7909\n",
      "Epoch 122/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5237 - categorical_accuracy: 0.7968\n",
      "Epoch 123/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5301 - categorical_accuracy: 0.7850\n",
      "Epoch 124/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5179 - categorical_accuracy: 0.8048\n",
      "Epoch 125/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5252 - categorical_accuracy: 0.8012\n",
      "Epoch 126/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4852 - categorical_accuracy: 0.8158\n",
      "Epoch 127/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4977 - categorical_accuracy: 0.8012\n",
      "Epoch 128/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5802 - categorical_accuracy: 0.7828\n",
      "Epoch 129/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.5134 - categorical_accuracy: 0.8034\n",
      "Epoch 130/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4901 - categorical_accuracy: 0.8114\n",
      "Epoch 131/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4742 - categorical_accuracy: 0.8114\n",
      "Epoch 132/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4998 - categorical_accuracy: 0.8063\n",
      "Epoch 133/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4917 - categorical_accuracy: 0.8114\n",
      "Epoch 134/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4901 - categorical_accuracy: 0.8202\n",
      "Epoch 135/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5227 - categorical_accuracy: 0.7953\n",
      "Epoch 136/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.5033 - categorical_accuracy: 0.8026\n",
      "Epoch 137/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5043 - categorical_accuracy: 0.8085\n",
      "Epoch 138/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4675 - categorical_accuracy: 0.8217\n",
      "Epoch 139/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.4389 - categorical_accuracy: 0.8342\n",
      "Epoch 140/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4903 - categorical_accuracy: 0.8085\n",
      "Epoch 141/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5295 - categorical_accuracy: 0.7924\n",
      "Epoch 142/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.5017 - categorical_accuracy: 0.7968\n",
      "Epoch 143/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4495 - categorical_accuracy: 0.8283\n",
      "Epoch 144/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4977 - categorical_accuracy: 0.8085\n",
      "Epoch 145/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4963 - categorical_accuracy: 0.8056\n",
      "Epoch 146/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.5246 - categorical_accuracy: 0.7880\n",
      "Epoch 147/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4580 - categorical_accuracy: 0.8202\n",
      "Epoch 148/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4796 - categorical_accuracy: 0.8144\n",
      "Epoch 149/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4845 - categorical_accuracy: 0.8070\n",
      "Epoch 150/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4623 - categorical_accuracy: 0.8254\n",
      "Epoch 151/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4525 - categorical_accuracy: 0.8276\n",
      "Epoch 152/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4480 - categorical_accuracy: 0.8349\n",
      "Epoch 153/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4562 - categorical_accuracy: 0.8232\n",
      "Epoch 154/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4494 - categorical_accuracy: 0.8364\n",
      "Epoch 155/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4743 - categorical_accuracy: 0.8144\n",
      "Epoch 156/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.5022 - categorical_accuracy: 0.8136\n",
      "Epoch 157/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4925 - categorical_accuracy: 0.8129\n",
      "Epoch 158/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4576 - categorical_accuracy: 0.8298\n",
      "Epoch 159/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4845 - categorical_accuracy: 0.8034\n",
      "Epoch 160/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4794 - categorical_accuracy: 0.8195\n",
      "Epoch 161/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4612 - categorical_accuracy: 0.8173\n",
      "Epoch 162/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.5176 - categorical_accuracy: 0.7960\n",
      "Epoch 163/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4678 - categorical_accuracy: 0.8195\n",
      "Epoch 164/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.4106 - categorical_accuracy: 0.8459\n",
      "Epoch 165/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.4316 - categorical_accuracy: 0.8261\n",
      "Epoch 166/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.4354 - categorical_accuracy: 0.8232\n",
      "Epoch 167/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4242 - categorical_accuracy: 0.8320\n",
      "Epoch 168/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4635 - categorical_accuracy: 0.8195\n",
      "Epoch 169/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4304 - categorical_accuracy: 0.8364\n",
      "Epoch 170/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4245 - categorical_accuracy: 0.8357\n",
      "Epoch 171/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4562 - categorical_accuracy: 0.8166\n",
      "Epoch 172/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.4360 - categorical_accuracy: 0.8379\n",
      "Epoch 173/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4352 - categorical_accuracy: 0.8283\n",
      "Epoch 174/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4512 - categorical_accuracy: 0.8188\n",
      "Epoch 175/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4389 - categorical_accuracy: 0.8283\n",
      "Epoch 176/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4126 - categorical_accuracy: 0.8474\n",
      "Epoch 177/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4286 - categorical_accuracy: 0.8335\n",
      "Epoch 178/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4366 - categorical_accuracy: 0.8276\n",
      "Epoch 179/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4677 - categorical_accuracy: 0.8232\n",
      "Epoch 180/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.4347 - categorical_accuracy: 0.8276\n",
      "Epoch 181/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4491 - categorical_accuracy: 0.8247\n",
      "Epoch 182/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4412 - categorical_accuracy: 0.8188\n",
      "Epoch 183/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4024 - categorical_accuracy: 0.8577\n",
      "Epoch 184/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4032 - categorical_accuracy: 0.8452\n",
      "Epoch 185/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4480 - categorical_accuracy: 0.8371\n",
      "Epoch 186/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4438 - categorical_accuracy: 0.8261\n",
      "Epoch 187/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4690 - categorical_accuracy: 0.8151\n",
      "Epoch 188/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4606 - categorical_accuracy: 0.8136\n",
      "Epoch 189/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.4130 - categorical_accuracy: 0.8349\n",
      "Epoch 190/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4461 - categorical_accuracy: 0.8217\n",
      "Epoch 191/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.3917 - categorical_accuracy: 0.8518\n",
      "Epoch 192/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4161 - categorical_accuracy: 0.8401\n",
      "Epoch 193/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.4006 - categorical_accuracy: 0.8415\n",
      "Epoch 194/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4153 - categorical_accuracy: 0.8379\n",
      "Epoch 195/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4147 - categorical_accuracy: 0.8386\n",
      "Epoch 196/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4336 - categorical_accuracy: 0.8342\n",
      "Epoch 197/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3976 - categorical_accuracy: 0.8423\n",
      "Epoch 198/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4289 - categorical_accuracy: 0.8327\n",
      "Epoch 199/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4498 - categorical_accuracy: 0.7990\n",
      "Epoch 200/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4213 - categorical_accuracy: 0.8349\n",
      "Epoch 201/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3979 - categorical_accuracy: 0.8430\n",
      "Epoch 202/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4110 - categorical_accuracy: 0.8327\n",
      "Epoch 203/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4398 - categorical_accuracy: 0.8291\n",
      "Epoch 204/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4560 - categorical_accuracy: 0.8254\n",
      "Epoch 205/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4351 - categorical_accuracy: 0.8298\n",
      "Epoch 206/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4203 - categorical_accuracy: 0.8393\n",
      "Epoch 207/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4044 - categorical_accuracy: 0.8503\n",
      "Epoch 208/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4036 - categorical_accuracy: 0.8415\n",
      "Epoch 209/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4073 - categorical_accuracy: 0.8467\n",
      "Epoch 210/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4414 - categorical_accuracy: 0.8247\n",
      "Epoch 211/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3877 - categorical_accuracy: 0.8547\n",
      "Epoch 212/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4276 - categorical_accuracy: 0.8357\n",
      "Epoch 213/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4195 - categorical_accuracy: 0.8276\n",
      "Epoch 214/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3700 - categorical_accuracy: 0.8591\n",
      "Epoch 215/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3977 - categorical_accuracy: 0.8408\n",
      "Epoch 216/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3774 - categorical_accuracy: 0.8467\n",
      "Epoch 217/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4238 - categorical_accuracy: 0.8349\n",
      "Epoch 218/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4017 - categorical_accuracy: 0.8423\n",
      "Epoch 219/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3885 - categorical_accuracy: 0.8613\n",
      "Epoch 220/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3703 - categorical_accuracy: 0.8562\n",
      "Epoch 221/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4167 - categorical_accuracy: 0.8364\n",
      "Epoch 222/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4271 - categorical_accuracy: 0.8393\n",
      "Epoch 223/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3593 - categorical_accuracy: 0.8657\n",
      "Epoch 224/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.4011 - categorical_accuracy: 0.8562\n",
      "Epoch 225/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3822 - categorical_accuracy: 0.8511\n",
      "Epoch 226/500\n",
      "43/43 [==============================] - 2s 49ms/step - loss: 0.4057 - categorical_accuracy: 0.8379\n",
      "Epoch 227/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.4116 - categorical_accuracy: 0.8357\n",
      "Epoch 228/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.3883 - categorical_accuracy: 0.8503\n",
      "Epoch 229/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3991 - categorical_accuracy: 0.8459\n",
      "Epoch 230/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3995 - categorical_accuracy: 0.8525\n",
      "Epoch 231/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3796 - categorical_accuracy: 0.8584\n",
      "Epoch 232/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.4249 - categorical_accuracy: 0.8349\n",
      "Epoch 233/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3841 - categorical_accuracy: 0.8657\n",
      "Epoch 234/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4088 - categorical_accuracy: 0.8408\n",
      "Epoch 235/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3941 - categorical_accuracy: 0.8489\n",
      "Epoch 236/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3688 - categorical_accuracy: 0.8540\n",
      "Epoch 237/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3812 - categorical_accuracy: 0.8540\n",
      "Epoch 238/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4332 - categorical_accuracy: 0.8415\n",
      "Epoch 239/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3930 - categorical_accuracy: 0.8459\n",
      "Epoch 240/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3799 - categorical_accuracy: 0.8547\n",
      "Epoch 241/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3579 - categorical_accuracy: 0.8731\n",
      "Epoch 242/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3740 - categorical_accuracy: 0.8628\n",
      "Epoch 243/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3833 - categorical_accuracy: 0.8643\n",
      "Epoch 244/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3925 - categorical_accuracy: 0.8496\n",
      "Epoch 245/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3808 - categorical_accuracy: 0.8540\n",
      "Epoch 246/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3540 - categorical_accuracy: 0.8621\n",
      "Epoch 247/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3903 - categorical_accuracy: 0.8569\n",
      "Epoch 248/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.4069 - categorical_accuracy: 0.8452\n",
      "Epoch 249/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3777 - categorical_accuracy: 0.8613\n",
      "Epoch 250/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3557 - categorical_accuracy: 0.8723\n",
      "Epoch 251/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3724 - categorical_accuracy: 0.8584\n",
      "Epoch 252/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3862 - categorical_accuracy: 0.8635\n",
      "Epoch 253/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3793 - categorical_accuracy: 0.8577\n",
      "Epoch 254/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3474 - categorical_accuracy: 0.8621\n",
      "Epoch 255/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3783 - categorical_accuracy: 0.8665\n",
      "Epoch 256/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3862 - categorical_accuracy: 0.8533\n",
      "Epoch 257/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3729 - categorical_accuracy: 0.8562\n",
      "Epoch 258/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3562 - categorical_accuracy: 0.8723\n",
      "Epoch 259/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3319 - categorical_accuracy: 0.8753\n",
      "Epoch 260/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3852 - categorical_accuracy: 0.8606\n",
      "Epoch 261/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3838 - categorical_accuracy: 0.8511\n",
      "Epoch 262/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4044 - categorical_accuracy: 0.8423\n",
      "Epoch 263/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3577 - categorical_accuracy: 0.8694\n",
      "Epoch 264/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3721 - categorical_accuracy: 0.8540\n",
      "Epoch 265/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3844 - categorical_accuracy: 0.8511\n",
      "Epoch 266/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3748 - categorical_accuracy: 0.8569\n",
      "Epoch 267/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3320 - categorical_accuracy: 0.8731\n",
      "Epoch 268/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3515 - categorical_accuracy: 0.8701\n",
      "Epoch 269/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3556 - categorical_accuracy: 0.8613\n",
      "Epoch 270/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3766 - categorical_accuracy: 0.8569\n",
      "Epoch 271/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.4011 - categorical_accuracy: 0.8371\n",
      "Epoch 272/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3774 - categorical_accuracy: 0.8584\n",
      "Epoch 273/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3616 - categorical_accuracy: 0.8687\n",
      "Epoch 274/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3662 - categorical_accuracy: 0.8621\n",
      "Epoch 275/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3537 - categorical_accuracy: 0.8723\n",
      "Epoch 276/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3563 - categorical_accuracy: 0.8628\n",
      "Epoch 277/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3857 - categorical_accuracy: 0.8562\n",
      "Epoch 278/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3663 - categorical_accuracy: 0.8628\n",
      "Epoch 279/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3602 - categorical_accuracy: 0.8679\n",
      "Epoch 280/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3496 - categorical_accuracy: 0.8613\n",
      "Epoch 281/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3778 - categorical_accuracy: 0.8591\n",
      "Epoch 282/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3805 - categorical_accuracy: 0.8474\n",
      "Epoch 283/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3790 - categorical_accuracy: 0.8525\n",
      "Epoch 284/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3666 - categorical_accuracy: 0.8621\n",
      "Epoch 285/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3470 - categorical_accuracy: 0.8694\n",
      "Epoch 286/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3756 - categorical_accuracy: 0.8569\n",
      "Epoch 287/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3631 - categorical_accuracy: 0.8569\n",
      "Epoch 288/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3203 - categorical_accuracy: 0.8841\n",
      "Epoch 289/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3818 - categorical_accuracy: 0.8599\n",
      "Epoch 290/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3416 - categorical_accuracy: 0.8760\n",
      "Epoch 291/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3832 - categorical_accuracy: 0.8496\n",
      "Epoch 292/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3360 - categorical_accuracy: 0.8789\n",
      "Epoch 293/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3527 - categorical_accuracy: 0.8613\n",
      "Epoch 294/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3336 - categorical_accuracy: 0.8665\n",
      "Epoch 295/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3988 - categorical_accuracy: 0.8533\n",
      "Epoch 296/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3545 - categorical_accuracy: 0.8569\n",
      "Epoch 297/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3419 - categorical_accuracy: 0.8665\n",
      "Epoch 298/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3825 - categorical_accuracy: 0.8687\n",
      "Epoch 299/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3524 - categorical_accuracy: 0.8657\n",
      "Epoch 300/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3510 - categorical_accuracy: 0.8694\n",
      "Epoch 301/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3580 - categorical_accuracy: 0.8657\n",
      "Epoch 302/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3530 - categorical_accuracy: 0.8745\n",
      "Epoch 303/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3720 - categorical_accuracy: 0.8591\n",
      "Epoch 304/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3518 - categorical_accuracy: 0.8679\n",
      "Epoch 305/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3256 - categorical_accuracy: 0.8775\n",
      "Epoch 306/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3494 - categorical_accuracy: 0.8775\n",
      "Epoch 307/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3771 - categorical_accuracy: 0.8467\n",
      "Epoch 308/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3206 - categorical_accuracy: 0.8877\n",
      "Epoch 309/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3519 - categorical_accuracy: 0.8723\n",
      "Epoch 310/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3614 - categorical_accuracy: 0.8731\n",
      "Epoch 311/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3556 - categorical_accuracy: 0.8643\n",
      "Epoch 312/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3472 - categorical_accuracy: 0.8738\n",
      "Epoch 313/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3317 - categorical_accuracy: 0.8899\n",
      "Epoch 314/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3506 - categorical_accuracy: 0.8731\n",
      "Epoch 315/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3624 - categorical_accuracy: 0.8606\n",
      "Epoch 316/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3777 - categorical_accuracy: 0.8599\n",
      "Epoch 317/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3499 - categorical_accuracy: 0.8665\n",
      "Epoch 318/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3430 - categorical_accuracy: 0.8716\n",
      "Epoch 319/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.3276 - categorical_accuracy: 0.8819\n",
      "Epoch 320/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3663 - categorical_accuracy: 0.8687\n",
      "Epoch 321/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3493 - categorical_accuracy: 0.8694\n",
      "Epoch 322/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3549 - categorical_accuracy: 0.8709\n",
      "Epoch 323/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3638 - categorical_accuracy: 0.8569\n",
      "Epoch 324/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.3657 - categorical_accuracy: 0.8650\n",
      "Epoch 325/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.3663 - categorical_accuracy: 0.8621\n",
      "Epoch 326/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.3212 - categorical_accuracy: 0.8841\n",
      "Epoch 327/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3488 - categorical_accuracy: 0.8672\n",
      "Epoch 328/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.3105 - categorical_accuracy: 0.8841\n",
      "Epoch 329/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3283 - categorical_accuracy: 0.8841\n",
      "Epoch 330/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3312 - categorical_accuracy: 0.8841\n",
      "Epoch 331/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3566 - categorical_accuracy: 0.8701\n",
      "Epoch 332/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3213 - categorical_accuracy: 0.8833\n",
      "Epoch 333/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3362 - categorical_accuracy: 0.8870\n",
      "Epoch 334/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3341 - categorical_accuracy: 0.8826\n",
      "Epoch 335/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3382 - categorical_accuracy: 0.8789\n",
      "Epoch 336/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3952 - categorical_accuracy: 0.8503\n",
      "Epoch 337/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3561 - categorical_accuracy: 0.8613\n",
      "Epoch 338/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3361 - categorical_accuracy: 0.8709\n",
      "Epoch 339/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3190 - categorical_accuracy: 0.8848\n",
      "Epoch 340/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3194 - categorical_accuracy: 0.8826\n",
      "Epoch 341/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3188 - categorical_accuracy: 0.8694\n",
      "Epoch 342/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3293 - categorical_accuracy: 0.8819\n",
      "Epoch 343/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3534 - categorical_accuracy: 0.8672\n",
      "Epoch 344/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3161 - categorical_accuracy: 0.8855\n",
      "Epoch 345/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3043 - categorical_accuracy: 0.8892\n",
      "Epoch 346/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3121 - categorical_accuracy: 0.8819\n",
      "Epoch 347/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3226 - categorical_accuracy: 0.8797\n",
      "Epoch 348/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3127 - categorical_accuracy: 0.8944\n",
      "Epoch 349/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3819 - categorical_accuracy: 0.8621\n",
      "Epoch 350/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3321 - categorical_accuracy: 0.8811\n",
      "Epoch 351/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3362 - categorical_accuracy: 0.8789\n",
      "Epoch 352/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3443 - categorical_accuracy: 0.8672\n",
      "Epoch 353/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3232 - categorical_accuracy: 0.8833\n",
      "Epoch 354/500\n",
      "43/43 [==============================] - 2s 50ms/step - loss: 0.3426 - categorical_accuracy: 0.8665\n",
      "Epoch 355/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3064 - categorical_accuracy: 0.8885\n",
      "Epoch 356/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3196 - categorical_accuracy: 0.8855\n",
      "Epoch 357/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3456 - categorical_accuracy: 0.8687\n",
      "Epoch 358/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3459 - categorical_accuracy: 0.8657\n",
      "Epoch 359/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3415 - categorical_accuracy: 0.8723\n",
      "Epoch 360/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.3412 - categorical_accuracy: 0.8797\n",
      "Epoch 361/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3097 - categorical_accuracy: 0.8936\n",
      "Epoch 362/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3275 - categorical_accuracy: 0.8767\n",
      "Epoch 363/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3062 - categorical_accuracy: 0.8936\n",
      "Epoch 364/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3132 - categorical_accuracy: 0.8892\n",
      "Epoch 365/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3214 - categorical_accuracy: 0.8753\n",
      "Epoch 366/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2885 - categorical_accuracy: 0.8907\n",
      "Epoch 367/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3115 - categorical_accuracy: 0.8841\n",
      "Epoch 368/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3136 - categorical_accuracy: 0.8855\n",
      "Epoch 369/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3466 - categorical_accuracy: 0.8863\n",
      "Epoch 370/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3254 - categorical_accuracy: 0.8833\n",
      "Epoch 371/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3071 - categorical_accuracy: 0.8775\n",
      "Epoch 372/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3798 - categorical_accuracy: 0.8694\n",
      "Epoch 373/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3996 - categorical_accuracy: 0.8459\n",
      "Epoch 374/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3871 - categorical_accuracy: 0.8511\n",
      "Epoch 375/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3554 - categorical_accuracy: 0.8628\n",
      "Epoch 376/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3338 - categorical_accuracy: 0.8657\n",
      "Epoch 377/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3520 - categorical_accuracy: 0.8694\n",
      "Epoch 378/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3647 - categorical_accuracy: 0.8672\n",
      "Epoch 379/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3513 - categorical_accuracy: 0.8701\n",
      "Epoch 380/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3618 - categorical_accuracy: 0.8547\n",
      "Epoch 381/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3693 - categorical_accuracy: 0.8643\n",
      "Epoch 382/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3336 - categorical_accuracy: 0.8738\n",
      "Epoch 383/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3519 - categorical_accuracy: 0.8804\n",
      "Epoch 384/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3243 - categorical_accuracy: 0.8936\n",
      "Epoch 385/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3647 - categorical_accuracy: 0.8679\n",
      "Epoch 386/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3432 - categorical_accuracy: 0.8643\n",
      "Epoch 387/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3424 - categorical_accuracy: 0.8775\n",
      "Epoch 388/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3311 - categorical_accuracy: 0.8841\n",
      "Epoch 389/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3217 - categorical_accuracy: 0.8797\n",
      "Epoch 390/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3223 - categorical_accuracy: 0.8760\n",
      "Epoch 391/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3227 - categorical_accuracy: 0.8789\n",
      "Epoch 392/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3026 - categorical_accuracy: 0.8892\n",
      "Epoch 393/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3060 - categorical_accuracy: 0.8848\n",
      "Epoch 394/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3791 - categorical_accuracy: 0.8599\n",
      "Epoch 395/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3596 - categorical_accuracy: 0.8709\n",
      "Epoch 396/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3097 - categorical_accuracy: 0.8848\n",
      "Epoch 397/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3716 - categorical_accuracy: 0.8650\n",
      "Epoch 398/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3326 - categorical_accuracy: 0.8701\n",
      "Epoch 399/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3599 - categorical_accuracy: 0.8584\n",
      "Epoch 400/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3388 - categorical_accuracy: 0.8782\n",
      "Epoch 401/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3469 - categorical_accuracy: 0.8687\n",
      "Epoch 402/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3333 - categorical_accuracy: 0.8753\n",
      "Epoch 403/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3502 - categorical_accuracy: 0.8694\n",
      "Epoch 404/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3528 - categorical_accuracy: 0.8613\n",
      "Epoch 405/500\n",
      "43/43 [==============================] - 2s 49ms/step - loss: 0.3200 - categorical_accuracy: 0.8782\n",
      "Epoch 406/500\n",
      "43/43 [==============================] - 2s 48ms/step - loss: 0.3188 - categorical_accuracy: 0.8826\n",
      "Epoch 407/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2980 - categorical_accuracy: 0.8797\n",
      "Epoch 408/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3521 - categorical_accuracy: 0.8789\n",
      "Epoch 409/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3216 - categorical_accuracy: 0.8804\n",
      "Epoch 410/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2930 - categorical_accuracy: 0.8936\n",
      "Epoch 411/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3384 - categorical_accuracy: 0.8731\n",
      "Epoch 412/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3383 - categorical_accuracy: 0.8716\n",
      "Epoch 413/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3160 - categorical_accuracy: 0.8760\n",
      "Epoch 414/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3191 - categorical_accuracy: 0.8731\n",
      "Epoch 415/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3365 - categorical_accuracy: 0.8760\n",
      "Epoch 416/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3261 - categorical_accuracy: 0.8767\n",
      "Epoch 417/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3073 - categorical_accuracy: 0.8826\n",
      "Epoch 418/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3069 - categorical_accuracy: 0.8921\n",
      "Epoch 419/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3026 - categorical_accuracy: 0.8848\n",
      "Epoch 420/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3269 - categorical_accuracy: 0.8782\n",
      "Epoch 421/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3320 - categorical_accuracy: 0.8811\n",
      "Epoch 422/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3179 - categorical_accuracy: 0.8767\n",
      "Epoch 423/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3549 - categorical_accuracy: 0.8569\n",
      "Epoch 424/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2995 - categorical_accuracy: 0.8907\n",
      "Epoch 425/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3574 - categorical_accuracy: 0.8672\n",
      "Epoch 426/500\n",
      "43/43 [==============================] - 2s 44ms/step - loss: 0.3324 - categorical_accuracy: 0.8819\n",
      "Epoch 427/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2959 - categorical_accuracy: 0.8921\n",
      "Epoch 428/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3264 - categorical_accuracy: 0.8760\n",
      "Epoch 429/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3097 - categorical_accuracy: 0.8841\n",
      "Epoch 430/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2949 - categorical_accuracy: 0.8892\n",
      "Epoch 431/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3106 - categorical_accuracy: 0.8841\n",
      "Epoch 432/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3628 - categorical_accuracy: 0.8621\n",
      "Epoch 433/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3178 - categorical_accuracy: 0.8855\n",
      "Epoch 434/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3442 - categorical_accuracy: 0.8775\n",
      "Epoch 435/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2841 - categorical_accuracy: 0.8966\n",
      "Epoch 436/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3487 - categorical_accuracy: 0.8775\n",
      "Epoch 437/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3385 - categorical_accuracy: 0.8789\n",
      "Epoch 438/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3097 - categorical_accuracy: 0.8797\n",
      "Epoch 439/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2960 - categorical_accuracy: 0.8958\n",
      "Epoch 440/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3183 - categorical_accuracy: 0.8833\n",
      "Epoch 441/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3041 - categorical_accuracy: 0.8826\n",
      "Epoch 442/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.3167 - categorical_accuracy: 0.8745\n",
      "Epoch 443/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3096 - categorical_accuracy: 0.8826\n",
      "Epoch 444/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2831 - categorical_accuracy: 0.8951\n",
      "Epoch 445/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3210 - categorical_accuracy: 0.8819\n",
      "Epoch 446/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3818 - categorical_accuracy: 0.8511\n",
      "Epoch 447/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3115 - categorical_accuracy: 0.8907\n",
      "Epoch 448/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3128 - categorical_accuracy: 0.8855\n",
      "Epoch 449/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3236 - categorical_accuracy: 0.8811\n",
      "Epoch 450/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2993 - categorical_accuracy: 0.8877\n",
      "Epoch 451/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2749 - categorical_accuracy: 0.8973\n",
      "Epoch 452/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3000 - categorical_accuracy: 0.8848\n",
      "Epoch 453/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2862 - categorical_accuracy: 0.8988\n",
      "Epoch 454/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3072 - categorical_accuracy: 0.8841\n",
      "Epoch 455/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3044 - categorical_accuracy: 0.8951\n",
      "Epoch 456/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2955 - categorical_accuracy: 0.8907\n",
      "Epoch 457/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3331 - categorical_accuracy: 0.8709\n",
      "Epoch 458/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3034 - categorical_accuracy: 0.8899\n",
      "Epoch 459/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3269 - categorical_accuracy: 0.8650\n",
      "Epoch 460/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2933 - categorical_accuracy: 0.8797\n",
      "Epoch 461/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2869 - categorical_accuracy: 0.8907\n",
      "Epoch 462/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.2856 - categorical_accuracy: 0.8951\n",
      "Epoch 463/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2901 - categorical_accuracy: 0.8899\n",
      "Epoch 464/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.2751 - categorical_accuracy: 0.9068\n",
      "Epoch 465/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2655 - categorical_accuracy: 0.9010\n",
      "Epoch 466/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3697 - categorical_accuracy: 0.8716\n",
      "Epoch 467/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3177 - categorical_accuracy: 0.8870\n",
      "Epoch 468/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2747 - categorical_accuracy: 0.9002\n",
      "Epoch 469/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2997 - categorical_accuracy: 0.8995\n",
      "Epoch 470/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3092 - categorical_accuracy: 0.8936\n",
      "Epoch 471/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2774 - categorical_accuracy: 0.8995\n",
      "Epoch 472/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2799 - categorical_accuracy: 0.8944\n",
      "Epoch 473/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2781 - categorical_accuracy: 0.9054\n",
      "Epoch 474/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2875 - categorical_accuracy: 0.8892\n",
      "Epoch 475/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2736 - categorical_accuracy: 0.8944\n",
      "Epoch 476/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3204 - categorical_accuracy: 0.8870\n",
      "Epoch 477/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2876 - categorical_accuracy: 0.9046\n",
      "Epoch 478/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3120 - categorical_accuracy: 0.8848\n",
      "Epoch 479/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2782 - categorical_accuracy: 0.8921\n",
      "Epoch 480/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2956 - categorical_accuracy: 0.8936\n",
      "Epoch 481/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3572 - categorical_accuracy: 0.8694\n",
      "Epoch 482/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3513 - categorical_accuracy: 0.8679\n",
      "Epoch 483/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3062 - categorical_accuracy: 0.8914\n",
      "Epoch 484/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2873 - categorical_accuracy: 0.8921\n",
      "Epoch 485/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3291 - categorical_accuracy: 0.8738\n",
      "Epoch 486/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2513 - categorical_accuracy: 0.9032\n",
      "Epoch 487/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2895 - categorical_accuracy: 0.8988\n",
      "Epoch 488/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2744 - categorical_accuracy: 0.8929\n",
      "Epoch 489/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3031 - categorical_accuracy: 0.8877\n",
      "Epoch 490/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2919 - categorical_accuracy: 0.8885\n",
      "Epoch 491/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2576 - categorical_accuracy: 0.9032\n",
      "Epoch 492/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2782 - categorical_accuracy: 0.8944\n",
      "Epoch 493/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.2505 - categorical_accuracy: 0.9017\n",
      "Epoch 494/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2566 - categorical_accuracy: 0.9032\n",
      "Epoch 495/500\n",
      "43/43 [==============================] - 2s 45ms/step - loss: 0.3118 - categorical_accuracy: 0.8841\n",
      "Epoch 496/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3212 - categorical_accuracy: 0.8723\n",
      "Epoch 497/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2790 - categorical_accuracy: 0.8936\n",
      "Epoch 498/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.2927 - categorical_accuracy: 0.8936\n",
      "Epoch 499/500\n",
      "43/43 [==============================] - 2s 47ms/step - loss: 0.2821 - categorical_accuracy: 0.8944\n",
      "Epoch 500/500\n",
      "43/43 [==============================] - 2s 46ms/step - loss: 0.3697 - categorical_accuracy: 0.8687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x39fb809d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ea70195",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('actiontest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f802f49",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/actiontest.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39m/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/actiontest.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/h5py/_hl/files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    525\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    527\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[1;32m    528\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[1;32m    529\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    530\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[1;32m    531\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[1;32m    532\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 533\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39mswmr)\n\u001b[1;32m    535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages/h5py/_hl/files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[1;32m    225\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 226\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[1;32m    227\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    228\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/actiontest.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights('/Users/kevynkrancenblum/Desktop/Data Science/Final Project/Body_Language_recognition/actiontest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b9c0100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 16:59:49.251057: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 16:59:49.460930: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-04-08 16:59:49.526326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 189ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "cm=multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fffef21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a79b2991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0\n",
      "True Positives: 12\n",
      "True Negatives: 48\n",
      "False Positives: 6\n",
      "False Negatives: 6\n",
      "\n",
      "Class 1\n",
      "True Positives: 32\n",
      "True Negatives: 33\n",
      "False Positives: 6\n",
      "False Negatives: 1\n",
      "\n",
      "Class 2\n",
      "True Positives: 12\n",
      "True Negatives: 47\n",
      "False Positives: 4\n",
      "False Negatives: 9\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the true positives, true negatives, false positives, and false negatives for each class\n",
    "tn = cm[:, 0, 0]\n",
    "fp = cm[:, 0, 1]\n",
    "fn = cm[:, 1, 0]\n",
    "tp = cm[:, 1, 1]\n",
    "\n",
    "# Print the evaluation metrics for each class\n",
    "for i in range(len(action)):\n",
    "    print('Class', i)\n",
    "    print('True Positives:', tp[i])\n",
    "    print('True Negatives:', tn[i])\n",
    "    print('False Positives:', fp[i])\n",
    "    print('False Negatives:', fn[i])\n",
    "    print()\n",
    "\n",
    "# Plot the confusion matrices for each class\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for i in range(len(action)):\n",
    "    axs[i].imshow(cm[i], cmap='Blues')\n",
    "    axs[i].set_title('Class ' + str(i))\n",
    "    axs[i].set_xlabel('Predicted')\n",
    "    axs[i].set_ylabel('True')\n",
    "    tick_marks = np.arange(2)\n",
    "    axs[i].set_xticks(tick_marks)\n",
    "    axs[i].set_yticks(tick_marks)\n",
    "    axs[i].set_xticklabels(['No', 'Yes'])\n",
    "    axs[i].set_yticklabels(['No', 'Yes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "826f0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22528e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Happy\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n"
     ]
    }
   ],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(\"/Users/kevynkrancenblum/Desktop/Data Science/Final Project/VideoBody/Angry/BasmaAngryy.mp4\")\n",
    "#cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                predictions.append(np.argmax(res))\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "        if len(predictions) > 0:\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "                if res[np.argmax(res)] > threshold: \n",
    "                    if len(sentence) > 0: \n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8fbcdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Angry\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Sad\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Sad\n"
     ]
    }
   ],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.6\n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(\"/Users/kevynkrancenblum/Desktop/Data Science/Final Project/VideoBody/sad/avitalsad1.mp4\")\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        black_screen = np.zeros((image.shape[0], image.shape[1], 3), np.uint8)\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(black_screen, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                predictions.append(np.argmax(res))\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "                if res[np.argmax(res)] > threshold: \n",
    "                    if len(sentence) > 0: \n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, black_screen, colors)\n",
    "            \n",
    "        cv2.rectangle(black_screen, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(black_screen, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', black_screen)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f27e84c7fb4756fe30ebd2212452f90785c16891dd0ca65c023d02a7a434102"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
